{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sammii0207/sami/blob/main/INFO5731_Assignment_Four.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9"
      },
      "source": [
        "# **INFO5731 Assignment Four**\n",
        "\n",
        "In this assignment, you are required to conduct topic modeling, sentiment analysis based on **the dataset you created from assignment three**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF"
      },
      "source": [
        "# **Question 1: Topic Modeling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k"
      },
      "source": [
        "(30 points). This question is designed to help you develop a feel for the way topic modeling works, the connection to the human meanings of documents. Based on the dataset from assignment three, write a python program to **identify the top 10 topics in the dataset**. Before answering this question, please review the materials in lesson 8, especially the code for LDA, LSA, and BERTopic. The following information should be reported:\n",
        "\n",
        "(1) Features (text representation) used for topic modeling.\n",
        "\n",
        "(2) Top 10 clusters for topic modeling.\n",
        "\n",
        "(3) Summarize and describe the topic for each cluster. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuFPKhC0m1fd",
        "outputId": "7dadc2c7-1df1-499c-bf07-2aca2398a36a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 Topics:\n",
            "1. Leave knock gift rain sounding cameras included connected previous commit\n",
            "2. Leave knock gift rain sounding cameras included connected previous commit\n",
            "3. Activate fix concert moderate son situation wouldn neutral relocate games\n",
            "4. Leave knock gift rain sounding cameras included connected previous commit\n",
            "5. Activate looks sounded moderate fix alarms conversationally wouldn primary couldn\n",
            "6. Instantly kasa activate repeat sounded cylinder dimmed bulb glows switch\n",
            "7. Couldn activate general 40 way outlets life ahead wanted floor\n",
            "8. Leave knock gift rain sounding cameras included connected previous commit\n",
            "9. Seating briefing 15 close nearest barely makes telling respond difficult\n",
            "10. Moderate oblige activate concert mini fix ala led second area\n",
            "\n",
            "Top 10 Clusters:\n",
            "Cluster 3     5\n",
            "Cluster 5     1\n",
            "Cluster 9     1\n",
            "Cluster 10    1\n",
            "Cluster 7     1\n",
            "Cluster 6     1\n",
            "Name: Max, dtype: int64\n",
            "\n",
            "Cluster Summaries:\n",
            "\n",
            "Cluster 1 Summary: New review 4th comparison honest dot vs generation 2nd echo\n",
            "Series([], Name: clean_text, dtype: object)\n",
            "\n",
            "Cluster 2 Summary: New review 4th comparison honest dot vs generation 2nd echo\n",
            "Series([], Name: clean_text, dtype: object)\n",
            "\n",
            "Cluster 3 Summary: Comparison review 2nd dot generation echo 4th vs honest new\n",
            "0    This is an honest review and comparison of the...\n",
            "2    The new Echo 4th Gen is a big change in aesthe...\n",
            "4    A friend of mine recently gave me an echo. 2nd...\n",
            "6    Bought this to control my lights and fan in an...\n",
            "8    Small speaker with great clear sound. Iâ€™m not ...\n",
            "Name: clean_text, dtype: object\n",
            "\n",
            "Cluster 4 Summary: New review 4th comparison honest dot vs generation 2nd echo\n",
            "Series([], Name: clean_text, dtype: object)\n",
            "\n",
            "Cluster 5 Summary: Review 4th 2nd dot generation comparison honest echo vs new\n",
            "1    I have my apartment which is not a small apart...\n",
            "Name: clean_text, dtype: object\n",
            "\n",
            "Cluster 6 Summary: New 2nd vs generation honest 4th echo dot comparison review\n",
            "9    I have 8 Echos in various rooms and from sever...\n",
            "Name: clean_text, dtype: object\n",
            "\n",
            "Cluster 7 Summary: Vs comparison honest dot review 4th echo new generation 2nd\n",
            "7    Bear with me...It all started with me wanting ...\n",
            "Name: clean_text, dtype: object\n",
            "\n",
            "Cluster 8 Summary: New review 4th comparison honest dot vs generation 2nd echo\n",
            "Series([], Name: clean_text, dtype: object)\n",
            "\n",
            "Cluster 9 Summary: Dot review 2nd echo new comparison generation vs 4th honest\n",
            "3    I bought 2 of these as refurbished, to add to ...\n",
            "Name: clean_text, dtype: object\n",
            "\n",
            "Cluster 10 Summary: Echo new generation vs 4th review 2nd dot comparison honest\n",
            "5    I have had homepod mini, the original homepod,...\n",
            "Name: clean_text, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# I have Used LDA for Topic Modeling.\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "df = pd.read_csv('annotated_amazon_reviews.csv')\n",
        "\n",
        "vectorizer = CountVectorizer(stop_words='english', max_features=5000)\n",
        "X = vectorizer.fit_transform(df['clean_text'])\n",
        "\n",
        "# Topic modeling with Latent Dirichlet Allocation (LDA)\n",
        "lda = LatentDirichletAllocation(n_components=10, random_state=42)\n",
        "lda.fit(X)\n",
        "\n",
        "def get_topic_title(topic):\n",
        "    words = topic\n",
        "    words = [list(vectorizer.vocabulary_.keys())[i] for i in words.argsort()[:-11:-1]]\n",
        "    return ' '.join(words).capitalize()\n",
        "\n",
        "print('Top 10 Topics:')\n",
        "for i, topic in enumerate(lda.components_):\n",
        "    print(f'{i+1}. {get_topic_title(topic)}')\n",
        "\n",
        "print('\\nTop 10 Clusters:')\n",
        "clusters = lda.transform(X)\n",
        "df_clusters = pd.DataFrame(clusters, columns=[f'Cluster {i+1}' for i in range(10)])\n",
        "df_clusters['Max'] = df_clusters.idxmax(axis=1)\n",
        "print(df_clusters['Max'].value_counts().head(10))\n",
        "\n",
        "print('\\nCluster Summaries:')\n",
        "for i in range(10):\n",
        "    print(f'\\nCluster {i+1} Summary: {get_topic_title(lda.components_.argsort()[:, ::-1][i, :10])}')\n",
        "    print(df[df_clusters['Max'] == f'Cluster {i+1}']['clean_text'].head(5))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z"
      },
      "source": [
        "# **Question 2: Sentiment Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw"
      },
      "source": [
        "(30 points). Sentiment analysis also known as opinion mining is a sub field within Natural Language Processing (NLP) that builds machine learning algorithms to classify a text according to the sentimental polarities of opinions it contains, e.g., positive, negative, neutral. The purpose of this question is to develop a machine learning classifier for sentiment analysis. Based on the dataset from assignment three, write a python program to implement a sentiment classifier and evaluate its performance. Notice: **80% data for training and 20% data for testing**.  \n",
        "\n",
        "(1) Features used for sentiment classification and explain why you select these features.\n",
        "\n",
        "(2) Select two of the supervised learning algorithm from scikit-learn library: https://scikit-learn.org/stable/supervised_learning.html#supervised-learning, to build a sentiment classifier respectively. Note: Cross-validation (5-fold or 10-fold) should be conducted. Here is the reference of cross-validation: https://scikit-learn.org/stable/modules/cross_validation.html.\n",
        "\n",
        "(3) Compare the performance over accuracy, precision, recall, and F1 score for the two algorithms you selected. Here is the reference of how to calculate these metrics: https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vATjQNTY8buA",
        "outputId": "911fe7f6-dc98-4cd7-edaf-f6b985228ce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Classifier:\n",
            "Accuracy: 0.5\n",
            "Precision: 1.0\n",
            "Recall: 0.5\n",
            "F1 score: 0.6666666666666666\n",
            "\n",
            "SVM Classifier:\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 score: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "''' In this code, the features used for sentiment analysis are the frequency of occurrence of words in the text data.\n",
        "These features are obtained using the CountVectorizer class from the scikit-learn library. '''\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "df = pd.read_csv('annotated_amazon_reviews.csv')\n",
        "\n",
        "vectorizer = CountVectorizer(stop_words='english', max_features=5000)\n",
        "X = vectorizer.fit_transform(df['clean_text'])\n",
        "y = df['sentiment']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "features = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Train and evaluate the Naive Bayes classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "nb_predictions = nb_classifier.predict(X_test)\n",
        "print('Naive Bayes Classifier:')\n",
        "print(f'Accuracy: {accuracy_score(y_test, nb_predictions)}')\n",
        "print(f'Precision: {precision_score(y_test, nb_predictions, pos_label=\"positive\")}')\n",
        "print(f'Recall: {recall_score(y_test, nb_predictions, pos_label=\"positive\")}')\n",
        "print(f'F1 score: {f1_score(y_test, nb_predictions, pos_label=\"positive\")}')\n",
        "\n",
        "# Train and evaluate the SVM classifier with 5-folds cross validation\n",
        "svm_classifier = SVC()\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "grid_search = GridSearchCV(svm_classifier, param_grid, cv=StratifiedKFold(n_splits=3), n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "svm_predictions = grid_search.predict(X_test)\n",
        "\n",
        "print('\\nSVM Classifier:')\n",
        "print(f'Accuracy: {accuracy_score(y_test, svm_predictions)}')\n",
        "print(f'Precision: {precision_score(y_test, svm_predictions, pos_label=\"positive\")}')\n",
        "print(f'Recall: {recall_score(y_test, svm_predictions, pos_label=\"positive\")}')\n",
        "print(f'F1 score: {f1_score(y_test, svm_predictions, pos_label=\"positive\")}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV"
      },
      "source": [
        "# **Question 3: House price prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX"
      },
      "source": [
        "(40 points). You are required to build a **regression** model to predict the house price with 79 explanatory variables describing (almost) every aspect of residential homes. The purpose of this question is to practice regression analysis, an supervised learning model. The training data, testing data, and data description files can be download from canvas. Here is an axample for implementation: https://towardsdatascience.com/linear-regression-in-python-predict-the-bay-areas-home-price-5c91c8378878. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfvMKJjIXS5G",
        "outputId": "18937cb3-61e7-475c-adaf-6da20455902f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-44-d91a7f576d5b>:18: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  combined_df.fillna(combined_df.mean(), inplace=True)\n",
            "<ipython-input-44-d91a7f576d5b>:50: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test_df['SalePrice'] = predictions\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation set RMSE: 4.041821481892244e+16\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "test_df['SalePrice'] = -1\n",
        "\n",
        "combined_df = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
        "\n",
        "''' Preprocessing Data, Here in this step we add the missing columns to test.csv  with placeholder values of 0 and 1 to align with that train.csv columns'''\n",
        "combined_df.fillna(combined_df.mean(), inplace=True)\n",
        "\n",
        "combined_df = pd.get_dummies(combined_df)\n",
        "\n",
        "train_df = combined_df[combined_df['SalePrice'] != -1]\n",
        "test_df = combined_df[combined_df['SalePrice'] == -1]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "train_df_scaled = scaler.fit_transform(train_df.drop(['SalePrice'], axis=1))\n",
        "test_df_scaled = scaler.transform(test_df.drop(['SalePrice'], axis=1))\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_df_scaled, train_df['SalePrice'], test_size=0.2, random_state=42)\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "y_val_pred = lr.predict(X_val)\n",
        "\n",
        "\n",
        "rmse = mean_squared_error(y_val, y_val_pred, squared=False)\n",
        "print('Validation set RMSE:', rmse)\n",
        "\n",
        "predictions = lr.predict(test_df_scaled)\n",
        "\n",
        "# Adds the saleprice column to test.csv file \n",
        "test_df['SalePrice'] = predictions\n",
        "test_df.to_csv('test.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7oEKBZohJ3XJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}